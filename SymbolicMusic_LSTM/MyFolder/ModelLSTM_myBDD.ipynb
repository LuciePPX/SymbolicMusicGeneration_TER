{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "#Installing dependencies\n",
    "!pip install music21\n",
    "!apt-get install -y lilypond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import tensorflow \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from collections import Counter\n",
    "import random\n",
    "import IPython\n",
    "from IPython.display import Image, Audio\n",
    "import music21\n",
    "from music21 import *\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "%matplotlib inline\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(\"ignore\")\n",
    "np.random.seed(42)\n",
    "\n",
    "# Rajout de l'application MuseScore3 remplacement de Lilypond\n",
    "from music21 import environment\n",
    "environment.set('musescoreDirectPNGPath', r\"C:\\Program Files\\MuseScore 3\\bin\\MuseScore3.exe\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "téléchargement de la base de donnée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#téléchargement de la base de donnée\n",
    "filepath = \"../myBDDD_trompet/\"\n",
    "#Liste de tous les fichiers midi \n",
    "all_midis= []\n",
    "for f in os.listdir(filepath):\n",
    "    if f.endswith(\".mid\"):\n",
    "        tr = filepath+f\n",
    "        midi = converter.parse(tr)\n",
    "        all_midis.append(midi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction extraction des notes d'un dossier de plusieurs fichiers\n",
    "def extract_notes(file):\n",
    "    notes = []\n",
    "    pick = None\n",
    "    for j in file:\n",
    "        songs = instrument.partitionByInstrument(j)\n",
    "        for part in songs.parts:\n",
    "            pick = part.recurse()\n",
    "            for element in pick:\n",
    "                if isinstance(element, note.Note):\n",
    "                    notes.append(str(element.pitch))\n",
    "                elif isinstance(element, chord.Chord):\n",
    "                    #notes.append(\".\".join(str(n) for n in element.normalOrder))\n",
    "                    notes.append(\".\".join(note.nameWithOctave for note in element.pitches))\n",
    "                   \n",
    "    print(notes)           \n",
    "    return notes\n",
    "\n",
    "#Création du corpus des notes de tous les fichier midi \n",
    "Corpus= extract_notes(all_midis)\n",
    "print(\"Total des notes de trompettes dans la base de donnée\", len(Corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(Corpus))\n",
    "print(\"50 première note du corpus\", Corpus[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_melody_stream(snippet):\n",
    "    melody_stream = stream.Stream()\n",
    "    offset = 0\n",
    "\n",
    "    for chord_notes in snippet:\n",
    "        # Si l'élément est un accord (représenté par une chaîne de caractères)\n",
    "        if '.' in chord_notes:\n",
    "            notes = []\n",
    "            for note_str in chord_notes.split('.'):\n",
    "                note_snip = note.Note(note_str)\n",
    "                notes.append(note_snip)\n",
    "\n",
    "            chord_snip = chord.Chord(notes)\n",
    "            chord_snip.offset = offset\n",
    "            melody_stream.append(chord_snip)\n",
    "\n",
    "        # Si l'élément est une note individuelle\n",
    "        else:\n",
    "            note_snip = note.Note(chord_notes)\n",
    "            note_snip.offset = offset\n",
    "            melody_stream.append(note_snip)\n",
    "\n",
    "        offset += 1  # Ajustez ici le décalage entre chaque note ou accord\n",
    "\n",
    "    return melody_stream\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Corpus[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melody=create_melody_stream(Corpus[:50])\n",
    "melody.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation d'un disctionnaire de comptes\n",
    "count_num = Counter(Corpus)\n",
    "print(\"Total des notes différentes dans le coprus:\", len(count_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploration du disctionnaire\n",
    "Notes = list(count_num.keys())\n",
    "Recurrence = list(count_num.values())\n",
    "print(Recurrence)\n",
    "#Les recurrences des notes\n",
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)\n",
    "print(\"Moyenne des récurrences des notes du corpus:\", Average(Recurrence))\n",
    "print(\"Frequence d'apparition de la note la plus présente:\", max(Recurrence), \"fois\")\n",
    "print(\"Frequence d'apparition de la note la moins présente:\", min(Recurrence), \"fois\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# affichage de la répartition des notes\n",
    "plt.figure(figsize=(18,3),facecolor=\"#97BACB\")\n",
    "bins = np.arange(0,(max(Recurrence)), 50) \n",
    "plt.hist(Recurrence, bins=bins, color=\"#97BACB\")\n",
    "plt.axvline(x=100,color=\"#DBACC1\")\n",
    "plt.title(\"frequence de distribution des accords\")\n",
    "plt.xlabel(\"Frequence des accords\")\n",
    "plt.ylabel(\"nombre d'accord\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#récupération des accords rares\n",
    "rare_note = []\n",
    "for index, (key, value) in enumerate(count_num.items()):\n",
    "    if value < 5:\n",
    "        m =  key\n",
    "        rare_note.append(m)\n",
    "        \n",
    "print(\"nombres d'accord apparaissant moins de 5 fois:\", len(rare_note))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#elimination des notes rares dans le corpus\n",
    "\n",
    "for element in Corpus:\n",
    "    if element in rare_note:\n",
    "        Corpus.remove(element)\n",
    "\n",
    "print(\"taille du corpus après élimination :\", len(Corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Storing all the unique characters present in my corpus to bult a mapping dic. \n",
    "symb = sorted(list(set(Corpus)))\n",
    "\n",
    "L_corpus = len(Corpus) #length of corpus\n",
    "L_symb = len(symb) #length of total unique characters\n",
    "\n",
    "#Building dictionary to access the vocabulary from indices and vice versa\n",
    "mapping = dict((c, i) for i, c in enumerate(symb))\n",
    "reverse_mapping = dict((i, c) for i, c in enumerate(symb))\n",
    "\n",
    "\n",
    "\n",
    "print(\"total de note du corpus:\", L_corpus) #nombre total de caractères dans le texte.\n",
    "print(\"nombre de note unique:\", L_symb) #nombre total de caractères uniques présents dans le texte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the Corpus in equal length of strings and output target\n",
    "length = 40\n",
    "features = []\n",
    "targets = []\n",
    "for i in range(0, L_corpus - length, 1):\n",
    "    feature = Corpus[i:i + length]\n",
    "    target = Corpus[i + length]\n",
    "    features.append([mapping[j] for j in feature])\n",
    "    targets.append(mapping[target])\n",
    "    \n",
    "    \n",
    "L_datapoints = len(targets)\n",
    "print(\"nombre total de sequence:\", L_datapoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape X and normalize\n",
    "X = (np.reshape(features, (L_datapoints, length, 1)))/ float(L_symb)\n",
    "# one hot encode the output variable\n",
    "y = tensorflow.keras.utils.to_categorical(targets) \n",
    "\n",
    "#Taking out a subset of data to be used as seed\n",
    "X_train, X_seed, y_train, y_seed = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialising the Model\n",
    "model = Sequential()\n",
    "#Adding layers\n",
    "model.add(LSTM(512, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dense(256))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "#Compiling the model for training  \n",
    "opt = Adamax(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model's Summary               \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the Model\n",
    "history = model.fit(X_train, y_train, batch_size=256, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the learnings \n",
    "history_df = pd.DataFrame(history.history)\n",
    "fig = plt.figure(figsize=(15,4), facecolor=\"#97BACB\")\n",
    "fig.suptitle(\"Learning Plot of Model for Loss\")\n",
    "pl=sns.lineplot(data=history_df[\"loss\"],color=\"#444160\")\n",
    "pl.set(ylabel =\"Training Loss\")\n",
    "pl.set(xlabel =\"Epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Malody_Generator(Note_Count):\n",
    "    seed = X_seed[np.random.randint(0, len(X_seed) - 1)]\n",
    "    Music = \"\"\n",
    "    Notes_Generated=[]\n",
    "    for i in range(Note_Count):\n",
    "        seed = seed.reshape(1,length,1)\n",
    "        prediction = model.predict(seed, verbose=0)[0]\n",
    "        prediction = np.log(prediction) / 1.0 #diversity\n",
    "        exp_preds = np.exp(prediction)\n",
    "        prediction = exp_preds / np.sum(exp_preds)\n",
    "        index = np.argmax(prediction)\n",
    "        index_N = index/ float(L_symb)   \n",
    "        Notes_Generated.append(index)\n",
    "        Music = [reverse_mapping[char] for char in Notes_Generated]\n",
    "        seed = np.insert(seed[0],len(seed[0]),index_N)\n",
    "        seed = seed[1:]\n",
    "    #Now, we have music in form or a list of chords and notes and we want to be a midi file.\n",
    "    Melody = create_melody_stream(Music)\n",
    "    Melody_midi = stream.Stream(Melody)   \n",
    "    return Melody,Melody_midi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Melody,Melody_midi=Malody_Generator(100)\n",
    "Melody.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enregistrer le stream en midi \n",
    "\n",
    "Melody.write('midi', fp='./generer_trompet.mid')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
